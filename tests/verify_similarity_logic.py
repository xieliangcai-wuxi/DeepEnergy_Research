import sys
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import yaml
import torch
import holidays

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from src.data.similarity import SimilarityEngine

# è®¾ç½®ç»˜å›¾é£æ ¼
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def get_day_status(date_obj, holiday_obj):
    is_weekend = date_obj.weekday() >= 5
    is_holiday = date_obj in holiday_obj
    if is_holiday: return "ğŸ”´èŠ‚æ—¥"
    if is_weekend: return "ğŸŸ å‘¨æœ«"
    return "ğŸ”µå·¥ä½œæ—¥"

def preprocess_runtime_simulation(df, target_col):
    df = df.copy()
    df['time'] = pd.to_datetime(df['time'], utc=True)
    
    if target_col in df.columns:
        df['lag_24'] = df[target_col].shift(24).bfill()
        df['lag_168'] = df[target_col].shift(168).bfill()
    
    # åŠ¨æ€è®¡ç®—å­£èŠ‚æ€§ç‰¹å¾
    doy = df['time'].dt.dayofyear
    df['sin_doy'] = np.sin(2 * np.pi * doy / 365.0)
    df['cos_doy'] = np.cos(2 * np.pi * doy / 365.0)
    
    if 'is_holiday_int' not in df.columns:
        years = df['time'].dt.year.unique()
        es_holidays = holidays.Spain(years=years)
        def check_holiday(d):
            return 1.0 if (d in es_holidays or d.weekday() >= 5) else 0.0
        df['is_holiday_int'] = df['time'].dt.date.map({d: check_holiday(d) for d in df['time'].dt.date.unique()})
        
    years = df['time'].dt.year.unique()
    es_holidays = holidays.Spain(years=years)
    return df, es_holidays

def run_verification_report():
    out_dir = './test/similarity_check_ratio' # æ”¹ä¸ªæ–‡ä»¶å¤¹å
    if not os.path.exists(out_dir): os.makedirs(out_dir)
    
    print("\n" + "="*80)
    print("   ğŸ•µï¸â€â™€ï¸ ç›¸ä¼¼æ—¥é€»è¾‘éªŒè¯ (æ¯”ç‡ä¿®æ­£ç‰ˆ)   ")
    print("   æ ¸å¿ƒæ€æƒ³: ä¸æŠ„ç»å¯¹å€¼ï¼ŒåªæŠ„å˜åŒ–ç‡ (Ratio)")
    print("="*80)
    
    config_path = './configs/exp_main_ra_st_glru.yaml'
    if not os.path.exists(config_path): config_path = '../configs/exp_main_ra_st_glru.yaml'
    with open(config_path, 'r', encoding='utf-8') as f: config = yaml.safe_load(f)
    target_col = config['preprocessing']['target_col']
    
    print(">>> [Step 1] åŠ è½½æ•°æ®...")
    train_path = os.path.join(config['paths']['output_dir'], "train.csv")
    test_path = os.path.join(config['paths']['output_dir'], "test.csv")
    
    df_train, es_holidays = preprocess_runtime_simulation(pd.read_csv(train_path), target_col)
    df_test, _ = preprocess_runtime_simulation(pd.read_csv(test_path), target_col)
    
    # å®šä¹‰æœç´¢ç‰¹å¾ (å«å­£èŠ‚æ€§)
    all_cols = df_train.columns
    search_features = ['lag_24', 'lag_168', 'price actual', 'is_holiday_int', 'sin_doy', 'cos_doy']
    search_features.extend([c for c in all_cols if '_temp' in c])
    if target_col in search_features: search_features.remove(target_col)
    
    print(f"    âœ… æœç´¢ç‰¹å¾: {search_features}")
    
    print(f"\n>>> [Step 2] è®­ç»ƒå¼•æ“...")
    sim_engine = SimilarityEngine(config)
    sim_engine.fit(df_train, search_features)
    
    # æ¡ˆä¾‹åˆ†æ (è¿˜æ˜¯é‚£å‡ ä¸ª)
    target_dates = ['2018-08-12 12:00', '2018-08-15 12:00', '2018-08-07 12:00']
    
    print(f"\n>>> [Step 3] å¼€å§‹æ¡ˆä¾‹åˆ†æ (åº”ç”¨æ¯”ç‡ä¿®æ­£)...")
    
    for t_str in target_dates:
        target_ts = pd.to_datetime(t_str).tz_localize('UTC')
        idx = (df_test['time'] - target_ts).abs().idxmin()
        query_row = df_test.iloc[idx]
        query_time = query_row['time']
        
        # æœç´¢
        query_vals = query_row[search_features].values.reshape(1, -1)
        query_norm = sim_engine.scaler.transform(query_vals)
        indices = sim_engine.search(torch.tensor(query_norm, dtype=torch.float32), training_mode=False).numpy()[0][:3]
        
        # åŸºç¡€ä¿¡æ¯
        q_status = get_day_status(query_time.date(), es_holidays)
        q_load = query_row[target_col]
        q_lag = query_row['lag_24'] # è¿™æ˜¯é”šç‚¹ï¼
        
        print("\n" + "-"*80)
        print(f"ğŸ“… ç›®æ ‡æ—¥: {query_time.date()} ({q_status})")
        print("-" * 80)
        print(f"ã€é”šç‚¹ã€‘ æ˜¨å¤©è´Ÿè· (Lag24): {q_lag:.0f} MW")
        print(f"ã€çœŸå€¼ã€‘ {q_load:.0f} MW")
        
        plt.figure(figsize=(12, 6))
        
        # ç”»çœŸå€¼
        q_start = query_time.normalize()
        q_data = df_test[(df_test['time'] >= q_start) & (df_test['time'] < q_start + pd.Timedelta(days=1))]
        plt.plot(q_data['time'].dt.hour, q_data[target_col], 'k-', linewidth=3, label=f'çœŸå€¼', zorder=10)
        
        colors = ['#E63946', '#F4A261', '#2A9D8F']
        
        for rank, sim_idx in enumerate(indices):
            sim_row = df_train.iloc[sim_idx]
            sim_date = sim_row['time'].date()
            sim_status = get_day_status(sim_date, es_holidays)
            
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ¯”ç‡æ³• (Ratio Method) ---
            sim_lag = sim_row['lag_24']
            sim_actual = sim_row[target_col]
            
            # è®¡ç®—å†å²é‚£ä¸€å¤©çš„å˜åŒ–ç‡ (Ratio)
            # é˜²æ­¢åˆ†æ¯ä¸º0 (è™½ç„¶ä¸å¤ªå¯èƒ½)
            ratio = sim_actual / (sim_lag + 1e-5)
            
            # ç”¨ä»Šå¤©çš„ Lag * å†å²çš„ Ratio
            pred_load_ratio = q_lag * ratio
            
            # è®¡ç®—ç›´æ¥æ‹·è´çš„åå·® (Old Way)
            err_direct = abs(sim_actual - q_load) / q_load * 100
            # è®¡ç®—æ¯”ç‡æ³•çš„åå·® (New Way)
            err_ratio = abs(pred_load_ratio - q_load) / q_load * 100
            
            print(f"   ğŸ† Rank {rank+1}: {sim_date} ({sim_status})")
            print(f"      -> ç»å¯¹å€¼åå·®: {err_direct:.1f}% (ç›´æ¥æŠ„: {sim_actual:.0f})")
            print(f"      -> æ¯”ç‡æ³•åå·®: {err_ratio:.1f}% (ä¿®æ­£å: {pred_load_ratio:.0f}) {'âœ… æ”¹å–„' if err_ratio < err_direct else 'âš ï¸ æ¶åŒ–'}")
            
            # ç»˜å›¾ï¼šç”»å‡ºä¿®æ­£åçš„æ›²çº¿
            # æˆ‘ä»¬éœ€è¦æŠŠæ•´æ¡æ›²çº¿éƒ½ä¹˜ä¸Š (q_lag / sim_lag) è¿™ä¸ªç¼©æ”¾ç³»æ•°
            s_start = sim_row['time'].normalize()
            s_data = df_train[(df_train['time'] >= s_start) & (df_train['time'] < s_start + pd.Timedelta(days=1))]
            
            if len(s_data) > 0:
                # è®¡ç®—å…¨å¤©çš„ç¼©æ”¾ç³»æ•° (åŸºäº lag_24)
                # æ³¨æ„: è¿™é‡Œç®€åŒ–äº†ï¼Œå…¨å¤©éƒ½ç”¨åŒä¸€ä¸ª scaling factorã€‚
                # å®é™…ä¸Šæ¨¡å‹ä¼šåœ¨æ¯ä¸ª timestep åŠ¨æ€è°ƒæ•´ã€‚
                scale_factor = q_lag / (sim_lag + 1e-5)
                scaled_curve = s_data[target_col] * scale_factor
                
                plt.plot(s_data['time'].dt.hour, scaled_curve, 
                         linestyle='--', color=colors[rank], alpha=0.8,
                         label=f'Top-{rank+1} (ä¿®æ­£ç‰ˆ): {sim_date}')

        plt.title(f"ç›¸ä¼¼æ—¥ (æ¯”ç‡ä¿®æ­£ç‰ˆ): {query_time.date()}", fontsize=14)
        plt.xlabel("Hour")
        plt.ylabel("Load (MW)")
        plt.legend()
        plt.grid(True, alpha=0.3)
        save_name = os.path.join(out_dir, f"report_{query_time.date()}.png")
        plt.savefig(save_name)
        plt.close()
        print(f"   ğŸ“Š å›¾è¡¨: {save_name}")

if __name__ == "__main__":
    run_verification_report()